{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pricer.evaluate import evaluate\n",
    "from pricer.items import Item\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 800,000 training items, 10,000 validation items, 10,000 test items\n"
     ]
    }
   ],
   "source": [
    "LITE_MODE = False\n",
    "username = \"ed-donner\"\n",
    "dataset = f\"{username}/items_lite\" if LITE_MODE else f\"{username}/items_full\"\n",
    "train, val, test = Item.get_from_hub(dataset)\n",
    "print(f\"Loaded {len(train):,} training items, {len(val):,} validation items, {len(test):,} test items\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Decision Tree pipeline\n",
    "decision_tree_pipeline = Pipeline(steps=[\n",
    "    (\n",
    "        \"tfidf\",\n",
    "        TfidfVectorizer(\n",
    "                    max_features=2000,\n",
    "                    stop_words=\"english\",\n",
    "                    ngram_range=(1, 2),\n",
    "                    sublinear_tf=True\n",
    "                )\n",
    "    ),\n",
    "    (\n",
    "        \"model\",\n",
    "        DecisionTreeRegressor(max_depth=None, random_state=42)\n",
    "    )\n",
    "])\n",
    "\n",
    "# Random Forest pipeline\n",
    "random_forest_pipeline = Pipeline(steps=[\n",
    "    (\n",
    "        \"tfidf\",\n",
    "        TfidfVectorizer(\n",
    "                    max_features=2000,\n",
    "                    stop_words=\"english\",\n",
    "                    ngram_range=(1, 2),\n",
    "                    sublinear_tf=True\n",
    "                )\n",
    "    ),\n",
    "    (\n",
    "        \"model\",\n",
    "        RandomForestRegressor(n_estimators=100, max_depth=None, random_state=42)\n",
    "    )\n",
    "])\n",
    "\n",
    "# Gradient Boosting pipeline\n",
    "gradient_boosting_pipeline = Pipeline(steps=[\n",
    "    (\n",
    "        \"tfidf\",\n",
    "        TfidfVectorizer(\n",
    "                    max_features=2000,\n",
    "                    stop_words=\"english\",\n",
    "                    ngram_range=(1, 2),\n",
    "                    sublinear_tf=True\n",
    "                )\n",
    "    ),\n",
    "    (\n",
    "        \"model\",\n",
    "        GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "    )\n",
    "])\n",
    "# XGBoost pipeline\n",
    "xgboost_pipeline = Pipeline(steps=[\n",
    "    (\n",
    "        \"tfidf\",\n",
    "        TfidfVectorizer(\n",
    "                    max_features=2000,\n",
    "                    stop_words=\"english\",\n",
    "                    ngram_range=(1, 2),\n",
    "                    sublinear_tf=True\n",
    "                )\n",
    "    ),\n",
    "    (\n",
    "        \"model\",\n",
    "        XGBRegressor(\n",
    "            n_estimators=100,\n",
    "            learning_rate=0.1,\n",
    "            max_depth=3,\n",
    "            random_state=42,\n",
    "            objective='reg:squarederror'\n",
    "        )\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataframe(train, test):\n",
    "    train_df = [{\"text\": item.summary, \"price\": float(item.price)} for item in tqdm(train)]\n",
    "    test_df = [{\"text\": item.summary, \"price\": float(item.price)} for item in tqdm(test)]\n",
    "    return pd.DataFrame(train_df), pd.DataFrame(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a69f6eeffd54338940194420d5f3fc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/800000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d68c7e19199d438b80605f7eff6897cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df , test_df  = get_dataframe(train , test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree_pipeline.fit(train_df['text'], train_df['price'])\n",
    "random_forest_pipeline.fit(train_df['text'], train_df['price'])\n",
    "gradient_boosting_pipeline.fit(train_df['text'], train_df['price'])\n",
    "# xgboost_pipeline.fit(train_df['text'], train_df['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_dt(item):\n",
    "    return decision_tree_pipeline.predict([item.summary])[0]\n",
    "\n",
    "def predict_rf(item):\n",
    "    return random_forest_pipeline.predict([item.summary])[0]\n",
    "\n",
    "def predict_gb(item):\n",
    "    return gradient_boosting_pipeline.predict([item.summary])[0]\n",
    "\n",
    "def predict_xgb(item):\n",
    "    return xgboost_pipeline.predict([item.summary])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"models\", exist_ok=True)\n",
    "pipelines = {\n",
    "    \"decision_tree\": decision_tree_pipeline,\n",
    "    \"random_forest\": random_forest_pipeline,\n",
    "    \"gradient_boosting\": gradient_boosting_pipeline,\n",
    "    \"xgboost\": xgboost_pipeline\n",
    "}\n",
    "\n",
    "# Fit and save each pipeline\n",
    "for name, pipeline in pipelines.items():\n",
    "    # Save the pipeline as a .pkl file\n",
    "    with open(f\"models/{name}_pipeline.pkl\", \"wb\") as f:\n",
    "        pickle.dump(pipeline, f)\n",
    "\n",
    "    print(f\"{name} pipeline saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"models/decision_tree_pipeline.pkl\", \"rb\") as f:\n",
    "    decision_tree_pipeline = pickle.load(f)\n",
    "\n",
    "with open(\"models/random_forest_pipeline.pkl\", \"rb\") as f:\n",
    "    random_forest_pipeline = pickle.load(f)\n",
    "\n",
    "with open(\"models/gradient_boosting_pipeline.pkl\", \"rb\") as f:\n",
    "    gradient_boosting_pipeline = pickle.load(f)\n",
    "\n",
    "with open(\"models/xgboost_pipeline.pkl\", \"rb\") as f:\n",
    "    xgboost_pipeline = pickle.load(f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_dt(item):\n",
    "    return decision_tree_pipeline.predict([item.summary])[0]\n",
    "\n",
    "def predict_rf(item):\n",
    "    return random_forest_pipeline.predict([item.summary])[0]\n",
    "\n",
    "def predict_gb(item):\n",
    "    return gradient_boosting_pipeline.predict([item.summary])[0]\n",
    "\n",
    "def predict_xgb(item):\n",
    "    return xgboost_pipeline.predict([item.summary])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(predict_dt, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(predict_rf, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(predict_gb, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(predict_xgb, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We got 182$ from Random Forest which is best from these tree based models, we so far have got 169$ off from Ridge Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
